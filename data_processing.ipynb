{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410eda29",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd500cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-07 12:19:34,553 [INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from facial_emotion_recognition import EmotionRecognition\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logging.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c509968",
   "metadata": {},
   "source": [
    "## Silesian Deception Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df03e6",
   "metadata": {},
   "source": [
    "### Face detection and crop (YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf668a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(model, frame):\n",
    "    results = model(frame, verbose=False)\n",
    "    if not results or results[0].boxes is None:\n",
    "        return []\n",
    "    return results[0].boxes.xyxy.int().tolist()\n",
    "\n",
    "def face_crop(model, frame):\n",
    "    boxes = detect_faces(model, frame)\n",
    "\n",
    "    for _, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        face_crop = frame[y1:y2, x1:x2]\n",
    "        if face_crop.size == 0:\n",
    "            continue\n",
    "        return face_crop\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f8282",
   "metadata": {},
   "source": [
    "### Resize images to consistent size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4b9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame, size=(224, 224)):\n",
    "    return cv2.resize(frame, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41124",
   "metadata": {},
   "source": [
    "### Geometric face normalization with MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3ff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_normalization(frame, face_mesh):\n",
    "    LEFT_EYE_LANDMARKS = [33, 133]\n",
    "    RIGHT_EYE_LANDMARKS = [362, 263]\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if not results.multi_face_landmarks:\n",
    "        return frame\n",
    "\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    left_eye = np.array([[landmarks[i].x * w, landmarks[i].y * h] for i in LEFT_EYE_LANDMARKS]).mean(axis=0)\n",
    "    right_eye = np.array([[landmarks[i].x * w, landmarks[i].y * h] for i in RIGHT_EYE_LANDMARKS]).mean(axis=0)\n",
    "\n",
    "    dy = right_eye[1] - left_eye[1]\n",
    "    dx = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "    center = tuple(map(float, np.mean([left_eye, right_eye], axis=0)))\n",
    "    rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    aligned = cv2.warpAffine(frame, rot_mat, (w, h), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a155ee",
   "metadata": {},
   "source": [
    "### Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9dd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_probs(frame, emotion_detector):\n",
    "    if frame.ndim == 3:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    tensor = emotion_detector.transform(frame).unsqueeze(0).to(emotion_detector.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = emotion_detector.network(tensor)\n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {emotion_detector.emotions[i]: float(probs[i]) for i in range(len(probs))}\n",
    "\n",
    "def detect_emotions(frame, emotion_detector):\n",
    "    return get_emotion_probs(frame, emotion_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078f123",
   "metadata": {},
   "source": [
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb48240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, face_detector, emotion_detector, face_mesh, frame_skip, label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    logging.info(f'Processing video: {video_name}')\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_skip != 0:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        face = face_crop(face_detector, frame)\n",
    "        if face is None:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "\n",
    "        resized_face = resize_frame(face)\n",
    "        normalized_face = geometric_normalization(resized_face, face_mesh)\n",
    "        emotions = detect_emotions(normalized_face, emotion_detector)\n",
    "\n",
    "        results.append({\n",
    "            'video': video_name,\n",
    "            'frame_idx': frame_idx,\n",
    "            'deceptive': label,\n",
    "            **emotions\n",
    "        })\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    logging.info(f\"âœ… Finished video: {video_name} ({len(results)} frames processed)\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_dataset(root_dir='data/silesian_deception_dataset', out_path='processed_data/silesian_deception_dataset/emotions.csv', frame_skip=5, device=device, deception_folder='poli2video'):\n",
    "    logging.info(\"ðŸš€ Starting dataset processing...\")\n",
    "    face_detector = YOLO('model_weights/yolov8n-face.pt').to(device)\n",
    "    emotion_detector = EmotionRecognition(device='gpu' if device == 'cuda' else 'cpu')\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        refine_landmarks=True,\n",
    "        max_num_faces=1\n",
    "    ) as face_mesh:\n",
    "        for folder in tqdm(os.listdir(root_dir), desc=\"Processing folders\", file=sys.stdout):\n",
    "            folder_path = os.path.join(root_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "\n",
    "            for file in tqdm(os.listdir(folder_path), desc=f\"Processing videos in {folder}\", leave=False, file=sys.stdout, dynamic_ncols=True):\n",
    "                if not file.lower().endswith(\".avi\"):\n",
    "                    continue\n",
    "\n",
    "                video_path = os.path.join(folder_path, file)\n",
    "                label = folder.lower() == deception_folder\n",
    "                video_results = process_video(video_path, face_detector, emotion_detector, face_mesh, frame_skip, label)\n",
    "                dataset.extend(video_results)\n",
    "        \n",
    "    df = pd.DataFrame(dataset)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    logging.info(\"ðŸŽ‰ All videos processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed90b3",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693b7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:47:48,665 [INFO] ðŸš€ Starting dataset processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762458468.962017   22954 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762458469.004400   23005 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 580.95.05), renderer: NVIDIA GeForce RTX 2060/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Accuracy: 0.9565809379727686\n",
      "Processing folders:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762458469.006338   23004 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:47:49,011 [INFO] Processing video: person1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762458469.014857   23001 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 20:48:35,863 [INFO] âœ… Finished video: person1 (2377 frames processed)\n",
      "2025-11-06 20:48:35,866 [INFO] Processing video: person10\n",
      "2025-11-06 20:49:14,843 [INFO] âœ… Finished video: person10 (1992 frames processed)\n",
      "2025-11-06 20:49:14,846 [INFO] Processing video: person11\n",
      "2025-11-06 20:50:04,046 [INFO] âœ… Finished video: person11 (2520 frames processed)\n",
      "2025-11-06 20:50:04,050 [INFO] Processing video: person12\n",
      "2025-11-06 20:51:05,876 [INFO] âœ… Finished video: person12 (3153 frames processed)\n",
      "2025-11-06 20:51:05,880 [INFO] Processing video: person13\n",
      "2025-11-06 20:51:51,317 [INFO] âœ… Finished video: person13 (2310 frames processed)\n",
      "2025-11-06 20:51:51,320 [INFO] Processing video: person14\n",
      "2025-11-06 20:52:33,225 [INFO] âœ… Finished video: person14 (2132 frames processed)\n",
      "2025-11-06 20:52:33,235 [INFO] Processing video: person15\n",
      "2025-11-06 20:53:26,175 [INFO] âœ… Finished video: person15 (2688 frames processed)\n",
      "2025-11-06 20:53:26,186 [INFO] Processing video: person16\n",
      "2025-11-06 20:54:12,542 [INFO] âœ… Finished video: person16 (2347 frames processed)\n",
      "2025-11-06 20:54:12,552 [INFO] Processing video: person17\n",
      "2025-11-06 20:55:02,063 [INFO] âœ… Finished video: person17 (2499 frames processed)\n",
      "2025-11-06 20:55:02,074 [INFO] Processing video: person18\n",
      "2025-11-06 20:55:42,969 [INFO] âœ… Finished video: person18 (2058 frames processed)\n",
      "2025-11-06 20:55:42,980 [INFO] Processing video: person19\n",
      "2025-11-06 20:56:25,714 [INFO] âœ… Finished video: person19 (2157 frames processed)\n",
      "2025-11-06 20:56:25,725 [INFO] Processing video: person2\n",
      "2025-11-06 20:57:02,287 [INFO] âœ… Finished video: person2 (1862 frames processed)\n",
      "2025-11-06 20:57:02,297 [INFO] Processing video: person20\n",
      "2025-11-06 20:57:42,278 [INFO] âœ… Finished video: person20 (2023 frames processed)\n",
      "2025-11-06 20:57:42,288 [INFO] Processing video: person21\n",
      "2025-11-06 20:58:25,485 [INFO] âœ… Finished video: person21 (2196 frames processed)\n",
      "2025-11-06 20:58:25,496 [INFO] Processing video: person22\n",
      "2025-11-06 20:59:18,825 [INFO] âœ… Finished video: person22 (2702 frames processed)\n",
      "2025-11-06 20:59:18,835 [INFO] Processing video: person23\n",
      "2025-11-06 21:00:04,603 [INFO] âœ… Finished video: person23 (2318 frames processed)\n",
      "2025-11-06 21:00:04,613 [INFO] Processing video: person24\n",
      "2025-11-06 21:00:49,511 [INFO] âœ… Finished video: person24 (2288 frames processed)\n",
      "2025-11-06 21:00:49,521 [INFO] Processing video: person25\n",
      "2025-11-06 21:01:33,051 [INFO] âœ… Finished video: person25 (2193 frames processed)\n",
      "2025-11-06 21:01:33,062 [INFO] Processing video: person26\n",
      "2025-11-06 21:02:21,556 [INFO] âœ… Finished video: person26 (2460 frames processed)\n",
      "2025-11-06 21:02:21,567 [INFO] Processing video: person27\n",
      "2025-11-06 21:03:09,647 [INFO] âœ… Finished video: person27 (2268 frames processed)\n",
      "2025-11-06 21:03:09,658 [INFO] Processing video: person28\n",
      "2025-11-06 21:03:56,590 [INFO] âœ… Finished video: person28 (2368 frames processed)\n",
      "2025-11-06 21:03:56,601 [INFO] Processing video: person29\n",
      "2025-11-06 21:04:33,082 [INFO] âœ… Finished video: person29 (1869 frames processed)\n",
      "2025-11-06 21:04:33,093 [INFO] Processing video: person3\n",
      "2025-11-06 21:05:20,840 [INFO] âœ… Finished video: person3 (2420 frames processed)\n",
      "2025-11-06 21:05:20,850 [INFO] Processing video: person30\n",
      "2025-11-06 21:06:03,257 [INFO] âœ… Finished video: person30 (2132 frames processed)\n",
      "2025-11-06 21:06:03,267 [INFO] Processing video: person31\n",
      "2025-11-06 21:06:43,510 [INFO] âœ… Finished video: person31 (2022 frames processed)\n",
      "2025-11-06 21:06:43,521 [INFO] Processing video: person32\n",
      "2025-11-06 21:07:27,505 [INFO] âœ… Finished video: person32 (2231 frames processed)\n",
      "2025-11-06 21:07:27,515 [INFO] Processing video: person33\n",
      "2025-11-06 21:08:11,848 [INFO] âœ… Finished video: person33 (2255 frames processed)\n",
      "2025-11-06 21:08:11,859 [INFO] Processing video: person34\n",
      "2025-11-06 21:08:54,917 [INFO] âœ… Finished video: person34 (2177 frames processed)\n",
      "2025-11-06 21:08:54,928 [INFO] Processing video: person35\n",
      "2025-11-06 21:09:42,228 [INFO] âœ… Finished video: person35 (2428 frames processed)\n",
      "2025-11-06 21:09:42,238 [INFO] Processing video: person36\n",
      "2025-11-06 21:10:30,120 [INFO] âœ… Finished video: person36 (2467 frames processed)\n",
      "2025-11-06 21:10:30,131 [INFO] Processing video: person37\n",
      "2025-11-06 21:11:08,873 [INFO] âœ… Finished video: person37 (1985 frames processed)\n",
      "2025-11-06 21:11:08,884 [INFO] Processing video: person38\n",
      "2025-11-06 21:11:47,646 [INFO] âœ… Finished video: person38 (1985 frames processed)\n",
      "2025-11-06 21:11:47,656 [INFO] Processing video: person39\n",
      "2025-11-06 21:12:33,308 [INFO] âœ… Finished video: person39 (2318 frames processed)\n",
      "2025-11-06 21:12:33,319 [INFO] Processing video: person4\n",
      "2025-11-06 21:13:08,662 [INFO] âœ… Finished video: person4 (1796 frames processed)\n",
      "2025-11-06 21:13:08,673 [INFO] Processing video: person40\n",
      "2025-11-06 21:13:53,617 [INFO] âœ… Finished video: person40 (2297 frames processed)\n",
      "2025-11-06 21:13:53,628 [INFO] Processing video: person41\n",
      "2025-11-06 21:14:41,253 [INFO] âœ… Finished video: person41 (2432 frames processed)\n",
      "2025-11-06 21:14:41,263 [INFO] Processing video: person42\n",
      "2025-11-06 21:15:24,630 [INFO] âœ… Finished video: person42 (2208 frames processed)\n",
      "2025-11-06 21:15:24,640 [INFO] Processing video: person43\n",
      "2025-11-06 21:16:08,533 [INFO] âœ… Finished video: person43 (2233 frames processed)\n",
      "2025-11-06 21:16:08,544 [INFO] Processing video: person44\n",
      "2025-11-06 21:16:52,350 [INFO] âœ… Finished video: person44 (2232 frames processed)\n",
      "2025-11-06 21:16:52,361 [INFO] Processing video: person45\n",
      "2025-11-06 21:17:34,352 [INFO] âœ… Finished video: person45 (2127 frames processed)\n",
      "2025-11-06 21:17:34,363 [INFO] Processing video: person46\n",
      "2025-11-06 21:18:20,256 [INFO] âœ… Finished video: person46 (2338 frames processed)\n",
      "2025-11-06 21:18:20,266 [INFO] Processing video: person47\n",
      "2025-11-06 21:19:06,836 [INFO] âœ… Finished video: person47 (2361 frames processed)\n",
      "2025-11-06 21:19:06,847 [INFO] Processing video: person48\n",
      "2025-11-06 21:19:47,928 [INFO] âœ… Finished video: person48 (2086 frames processed)\n",
      "2025-11-06 21:19:47,939 [INFO] Processing video: person49\n",
      "2025-11-06 21:20:25,981 [INFO] âœ… Finished video: person49 (1920 frames processed)\n",
      "2025-11-06 21:20:25,992 [INFO] Processing video: person5\n",
      "2025-11-06 21:21:14,809 [INFO] âœ… Finished video: person5 (2470 frames processed)\n",
      "2025-11-06 21:21:14,820 [INFO] Processing video: person6\n",
      "2025-11-06 21:21:53,872 [INFO] âœ… Finished video: person6 (1999 frames processed)\n",
      "2025-11-06 21:21:53,882 [INFO] Processing video: person7\n",
      "2025-11-06 21:22:27,316 [INFO] âœ… Finished video: person7 (1715 frames processed)\n",
      "2025-11-06 21:22:27,327 [INFO] Processing video: person8\n",
      "2025-11-06 21:23:09,355 [INFO] âœ… Finished video: person8 (2150 frames processed)\n",
      "2025-11-06 21:23:09,366 [INFO] Processing video: person9\n",
      "2025-11-06 21:23:54,511 [INFO] âœ… Finished video: person9 (2311 frames processed)\n",
      "Processing folders:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [36:05<36:05, 2165.51s/it]2025-11-06 21:23:54,525 [INFO] Processing video: person1\n",
      "2025-11-06 21:24:41,701 [INFO] âœ… Finished video: person1 (2394 frames processed)\n",
      "2025-11-06 21:24:41,711 [INFO] Processing video: person10\n",
      "2025-11-06 21:25:26,991 [INFO] âœ… Finished video: person10 (2300 frames processed)\n",
      "2025-11-06 21:25:27,002 [INFO] Processing video: person11\n",
      "2025-11-06 21:26:06,600 [INFO] âœ… Finished video: person11 (2014 frames processed)\n",
      "2025-11-06 21:26:06,610 [INFO] Processing video: person12\n",
      "2025-11-06 21:26:46,605 [INFO] âœ… Finished video: person12 (2047 frames processed)\n",
      "2025-11-06 21:26:46,615 [INFO] Processing video: person13\n",
      "2025-11-06 21:27:30,027 [INFO] âœ… Finished video: person13 (2206 frames processed)\n",
      "2025-11-06 21:27:30,037 [INFO] Processing video: person15\n",
      "2025-11-06 21:28:10,945 [INFO] âœ… Finished video: person15 (2085 frames processed)\n",
      "2025-11-06 21:28:10,955 [INFO] Processing video: person16\n",
      "2025-11-06 21:28:46,781 [INFO] âœ… Finished video: person16 (1827 frames processed)\n",
      "2025-11-06 21:28:46,791 [INFO] Processing video: person17\n",
      "2025-11-06 21:29:19,700 [INFO] âœ… Finished video: person17 (1670 frames processed)\n",
      "2025-11-06 21:29:19,711 [INFO] Processing video: person18\n",
      "2025-11-06 21:30:03,184 [INFO] âœ… Finished video: person18 (2212 frames processed)\n",
      "2025-11-06 21:30:03,195 [INFO] Processing video: person19\n",
      "2025-11-06 21:30:39,283 [INFO] âœ… Finished video: person19 (1825 frames processed)\n",
      "2025-11-06 21:30:39,294 [INFO] Processing video: person2\n",
      "2025-11-06 21:31:42,021 [INFO] âœ… Finished video: person2 (3203 frames processed)\n",
      "2025-11-06 21:31:42,032 [INFO] Processing video: person20\n",
      "2025-11-06 21:32:15,211 [INFO] âœ… Finished video: person20 (1655 frames processed)\n",
      "2025-11-06 21:32:15,222 [INFO] Processing video: person21\n",
      "2025-11-06 21:32:55,679 [INFO] âœ… Finished video: person21 (2035 frames processed)\n",
      "2025-11-06 21:32:55,689 [INFO] Processing video: person22\n",
      "2025-11-06 21:33:31,459 [INFO] âœ… Finished video: person22 (1809 frames processed)\n",
      "2025-11-06 21:33:31,469 [INFO] Processing video: person23\n",
      "2025-11-06 21:34:05,314 [INFO] âœ… Finished video: person23 (1724 frames processed)\n",
      "2025-11-06 21:34:05,324 [INFO] Processing video: person24\n",
      "2025-11-06 21:34:40,550 [INFO] âœ… Finished video: person24 (1794 frames processed)\n",
      "2025-11-06 21:34:40,560 [INFO] Processing video: person25\n",
      "2025-11-06 21:35:18,209 [INFO] âœ… Finished video: person25 (1923 frames processed)\n",
      "2025-11-06 21:35:18,220 [INFO] Processing video: person26\n",
      "2025-11-06 21:36:10,195 [INFO] âœ… Finished video: person26 (2636 frames processed)\n",
      "2025-11-06 21:36:10,205 [INFO] Processing video: person27\n",
      "2025-11-06 21:36:40,542 [INFO] âœ… Finished video: person27 (1543 frames processed)\n",
      "2025-11-06 21:36:40,552 [INFO] Processing video: person28\n",
      "2025-11-06 21:37:18,355 [INFO] âœ… Finished video: person28 (1933 frames processed)\n",
      "2025-11-06 21:37:18,366 [INFO] Processing video: person29\n",
      "2025-11-06 21:37:55,823 [INFO] âœ… Finished video: person29 (1907 frames processed)\n",
      "2025-11-06 21:37:55,833 [INFO] Processing video: person3\n",
      "2025-11-06 21:38:37,592 [INFO] âœ… Finished video: person3 (2118 frames processed)\n",
      "2025-11-06 21:38:37,602 [INFO] Processing video: person30\n",
      "2025-11-06 21:39:14,234 [INFO] âœ… Finished video: person30 (1869 frames processed)\n",
      "2025-11-06 21:39:14,244 [INFO] Processing video: person31\n",
      "2025-11-06 21:39:48,465 [INFO] âœ… Finished video: person31 (1739 frames processed)\n",
      "2025-11-06 21:39:48,476 [INFO] Processing video: person32\n",
      "2025-11-06 21:40:30,754 [INFO] âœ… Finished video: person32 (2134 frames processed)\n",
      "2025-11-06 21:40:30,764 [INFO] Processing video: person33\n",
      "2025-11-06 21:41:10,063 [INFO] âœ… Finished video: person33 (1988 frames processed)\n",
      "2025-11-06 21:41:10,073 [INFO] Processing video: person34\n",
      "2025-11-06 21:41:50,151 [INFO] âœ… Finished video: person34 (2029 frames processed)\n",
      "2025-11-06 21:41:50,162 [INFO] Processing video: person35\n",
      "2025-11-06 21:42:32,643 [INFO] âœ… Finished video: person35 (2165 frames processed)\n",
      "2025-11-06 21:42:32,653 [INFO] Processing video: person36\n",
      "2025-11-06 21:43:11,099 [INFO] âœ… Finished video: person36 (1966 frames processed)\n",
      "2025-11-06 21:43:11,109 [INFO] Processing video: person37\n",
      "2025-11-06 21:43:54,117 [INFO] âœ… Finished video: person37 (2190 frames processed)\n",
      "2025-11-06 21:43:54,128 [INFO] Processing video: person38\n",
      "2025-11-06 21:44:34,041 [INFO] âœ… Finished video: person38 (2048 frames processed)\n",
      "2025-11-06 21:44:34,052 [INFO] Processing video: person39\n",
      "2025-11-06 21:45:12,327 [INFO] âœ… Finished video: person39 (1951 frames processed)\n",
      "2025-11-06 21:45:12,337 [INFO] Processing video: person4\n",
      "2025-11-06 21:46:00,721 [INFO] âœ… Finished video: person4 (2476 frames processed)\n",
      "2025-11-06 21:46:00,731 [INFO] Processing video: person5\n",
      "2025-11-06 21:46:35,937 [INFO] âœ… Finished video: person5 (1795 frames processed)\n",
      "2025-11-06 21:46:35,948 [INFO] Processing video: person6\n",
      "2025-11-06 21:47:07,828 [INFO] âœ… Finished video: person6 (1626 frames processed)\n",
      "2025-11-06 21:47:07,838 [INFO] Processing video: person7\n",
      "2025-11-06 21:47:47,781 [INFO] âœ… Finished video: person7 (2035 frames processed)\n",
      "2025-11-06 21:47:47,792 [INFO] Processing video: person8\n",
      "2025-11-06 21:48:23,259 [INFO] âœ… Finished video: person8 (1818 frames processed)\n",
      "2025-11-06 21:48:23,270 [INFO] Processing video: person9\n",
      "2025-11-06 21:49:03,283 [INFO] âœ… Finished video: person9 (2042 frames processed)\n",
      "Processing folders: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [1:01:14<00:00, 1837.14s/it]\n",
      "2025-11-06 21:49:04,936 [INFO] ðŸŽ‰ All videos processed successfully!\n"
     ]
    }
   ],
   "source": [
    "process_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7f212",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2ad099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>deceptive</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>person1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.309457</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.116338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>person1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.309557</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.115004</td>\n",
       "      <td>0.115422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>person1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.311774</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.114709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person1</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.311548</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.114834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>person1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.310822</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.116133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video  frame_idx  deceptive     Angry   Disgust      Fear     Happy  \\\n",
       "0  person1          0       True  0.114841  0.114841  0.114841  0.309457   \n",
       "1  person1          5       True  0.115004  0.115004  0.115004  0.309557   \n",
       "2  person1         10       True  0.114703  0.114703  0.114703  0.311774   \n",
       "3  person1         15       True  0.114724  0.114724  0.114724  0.311548   \n",
       "4  person1         20       True  0.114609  0.114609  0.114609  0.310822   \n",
       "\n",
       "        Sad  Surprise   Neutral  \n",
       "0  0.114841  0.114841  0.116338  \n",
       "1  0.115004  0.115004  0.115422  \n",
       "2  0.114703  0.114703  0.114709  \n",
       "3  0.114724  0.114724  0.114834  \n",
       "4  0.114609  0.114609  0.116133  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data/silesian_deception_dataset/emotions.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
